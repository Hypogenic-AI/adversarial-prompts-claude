idea:
  title: Is it easier or harder to hide adversarial prompts in longer documents?
  domain: nlp
  hypothesis: 'The effectiveness of hiding adversarial prompts within long documents
    depends on whether increased document length introduces noise that overrides the
    adversarial effect or provides more space to conceal such instructions.

    '
  background:
    description: We all know about the adversarial prompts that look like gibberish
      but get an LLM to do something like tell you how to build a bomb or simply write
      a python function. Is it easier or harder to hide such 'instructions' in very
      long documents? Does the document create noise that overrides the adversarial
      effect or does it give more room to work with?
  metadata:
    source: IdeaHub
    source_url: https://hypogenic.ai/ideahub/idea/RE4hPBZFPcPjlucQzkA8
    idea_id: is_it_easier_or_harder_to_hide_20260103_145819_00cc0661
    created_at: '2026-01-03T14:58:19.752897'
    status: submitted
    github_repo_name: adversarial-prompts-claude
    github_repo_url: https://github.com/Hypogenic-AI/adversarial-prompts-claude
